---
layout: post
title: AI and Marginal Gains
---
There's an uncomfortable paradox at the heart of Generative AI adoption: the promise from AI vendors and consultants like me is that the technology will boost productivity. And for the most part, this holds true with my clients. But the gains are unevenly distributed. [Dan Hon wrote in his newsletter recently that his friends who use LLMs brilliantly in their coding work do so because they bring very particular skills and experience that don't translate to the average user](https://newsletter.danhon.com/archive/s21e03-the-problem-is-defining-the-problem-the/)&#8212;a challenge amplified by what Ethan Mollick calls AI's 'jagged frontier' of uneven capabilities. Scale this up to enterprise level and you hit a bigger problem: AI can create efficiencies for individual, power users, but it doesn't necessarily deliver the company-wide transformation the C-suite was sold on. You've probably seen headlines claiming that most AI pilots fail to deliver measurable P&L impact. Are the promised gains genuinely elusive, or do we need to reframe what we're looking for?

I've been thinking about this differently lately, [prompted by something Matt Webb wrote about AI agents](https://interconnected.org/home/2026/01/15/reminders). There's an almost throwaway line: ['It feels like small beans, agents that do this kind of admin, but it adds up.'](https://interconnected.org/home/2026/01/15/reminders) That phrase&#8212;'it adds up'&#8212;stuck with me, because it suggests we've maybe been asking the wrong question. We've been looking for transformation when we should be looking for aggregation.

There’s an interesting parallel with sport. Back in the Before Time, when Team Sky and British Cycling were dominant, [there was a theory popularised by team principal Sir Dave Brailsford called 'the aggregation of marginal gains'](https://jamesclear.com/marginal-gains). Put simply, the intuition was that a single step-change in performance is hard to deliver, but that aggregating dozens of 1% micro-improvements could compound into equivalent, meaningful performance gains. I remember giving a presentation on it at the big company where I worked at the time: everyone loved it. Then, like most management fads, it fell out of fashion. [Alternative explanations emerged for Team Sky's success, not least that they outspent most rivals by a factor of two](https://www.theguardian.com/sport/blog/2019/oct/20/marginal-gains-tarnished-bradley-wiggins-dave-brailsford). 

I wonder though if the theory of marginal gains deserves a renaissance as a way of thinking about Generative AI and productivity. Not because the cycling analogy is perfect, but because it reframes expectations in a useful way. The question stops being the moonshot, 'will AI transform our organisation?' and becomes 'where can we make small, consistent improvements that compound over time?'

The critical part that I suspect most people miss is that marginal gains only work if you treat them as a system, not a lucky streak. Brailsford's riders didn't just change things and hope for the best. They built the discipline, measurement, and feedback loops to make tiny improvements stick, and they did so within an overall structure. The same applies to AI productivity.

Most people don't need&#8212;or want&#8212;a complete reinvention of their work with AI. What they need is to identify their own personal set of '1% improvements': tasks that are repeatable, low-friction, and genuinely cumulative. The ten minutes saved drafting the awkward email, the faster first pass on a report, the cleaner and faster meeting notes (all examples from my work today). This is the stuff that feels like small beans in Matt Webb's phrase, until you look back over a month and realise it's added half a day or a day of reclaimed capacity.

Identifying these gains requires reflection, not prescription. I can't give you a universal list of five AI tasks that will save you time, because your work isn't my work. It's highly context-dependent. What I can suggest is a simple framework for finding them yourself.

First, track one week of your work. Not a detailed time-and-motion study, not noting things to the minute like a lawyer tracking billable hours; just note when you're doing tasks that feel like they're taking a lot of time, that come up week after week, that drain energy disproportionate to their importance, or that you regularly put off doing. These are your marginal gains candidates. Start with low-risk tasks where a decent first pass is valuable, and mistakes are easy to catch. 

Second, experiment deliberately. Pick one of these tasks and spend a week testing whether an LLM can do it adequately. Not perfectly, adequately. Set a time limit, and if you haven't made it work in that time, move on. 

Third, track lightly but consistently. Brailsford succeeded through measurement, but there’s a balance between capturing detail and having any time saving eaten up by process measurement. A simple weekly reflection works: what AI helped with, roughly how much time was saved, and how you invested the time. Answer it honestly in a document somewhere. The act of writing it down creates accountability. This starts as a personal habit, but it's also how organisations make adoption repeatable, measurable and shareable. 

And this is where I think the marginal gains framework might actually address the uneven distribution problem. Power users aren't necessarily smarter about AI, [but as Dan Hon suggests, they're more deliberate about identifying where it helps them specifically](https://newsletter.danhon.com/archive/s21e03-the-problem-is-defining-the-problem-the/). If you give people a structured way to reflect on their own time utilisation and experiment within defined boundaries, you open up the benefits to more than just the naturally technical or the instinctively curious. The real productivity prize isn't 'doing the same work faster.' It's deciding what happens to the time you get back. If you don't ringfence it, it vanishes&#8212;swallowed by [Parkinson's Law](https://en.wikipedia.org/wiki/Parkinson%27s_law), more meetings, more email, more noise. The reclaimed time gets immediately repossessed by the urgent and the trivial.

So perhaps the right way to think about AI at work isn't as a silver bullet that transforms the whole organisation overnight. It's as a deliberate marginal gains programme: a few small interventions, identified personally, done consistently, tracked lightly, and used to create slack for higher-value work. The question then isn't whether AI can save you fifteen minutes. It's whether you can use those fifteen minutes in a way that compounds. 
